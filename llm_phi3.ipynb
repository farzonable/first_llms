{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOEdlXs5h8b3WP9Fc9qaPwl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a9ef4c3d58dd4da0b623438d7c5efc7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb7a52873adb4968beb231e023274c5f","IPY_MODEL_0fe7b24bdfab433e9039208a543e1aab","IPY_MODEL_2b3509cc11fd4e92b6f76528b953d1c5"],"layout":"IPY_MODEL_b6b9b4291c224d008e8bc9ae6bd8f75d"}},"eb7a52873adb4968beb231e023274c5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79bd593991724caba310e566e3f93ade","placeholder":"​","style":"IPY_MODEL_3c37ae1d60ae4ef8a242ad6a3626e1d5","value":"Loading checkpoint shards: 100%"}},"0fe7b24bdfab433e9039208a543e1aab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_521dcd0daef548f0bdd13b785974976b","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_460a0fe18ffa46768641096aed0add75","value":2}},"2b3509cc11fd4e92b6f76528b953d1c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45c6ea38cb2f41e58369a8790765cab4","placeholder":"​","style":"IPY_MODEL_3dcc80d1bf9345419fbadd0b6ffa0bab","value":" 2/2 [00:28&lt;00:00, 13.56s/it]"}},"b6b9b4291c224d008e8bc9ae6bd8f75d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79bd593991724caba310e566e3f93ade":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c37ae1d60ae4ef8a242ad6a3626e1d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"521dcd0daef548f0bdd13b785974976b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"460a0fe18ffa46768641096aed0add75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45c6ea38cb2f41e58369a8790765cab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dcc80d1bf9345419fbadd0b6ffa0bab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","# Load model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"microsoft/Phi-3-mini-4k-instruct\",\n","    device_map=\"cuda\",\n","    dtype=\"auto\",\n","    trust_remote_code=True\n",")\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["a9ef4c3d58dd4da0b623438d7c5efc7c","eb7a52873adb4968beb231e023274c5f","0fe7b24bdfab433e9039208a543e1aab","2b3509cc11fd4e92b6f76528b953d1c5","b6b9b4291c224d008e8bc9ae6bd8f75d","79bd593991724caba310e566e3f93ade","3c37ae1d60ae4ef8a242ad6a3626e1d5","521dcd0daef548f0bdd13b785974976b","460a0fe18ffa46768641096aed0add75","45c6ea38cb2f41e58369a8790765cab4","3dcc80d1bf9345419fbadd0b6ffa0bab"]},"executionInfo":{"status":"ok","timestamp":1761047466150,"user_tz":-120,"elapsed":58110,"user":{"displayName":"Working Gmail","userId":"11296043961252965758"}},"outputId":"b53a9674-4ff8-4fd2-f698-b5c6e66cf32a","id":"Z3iHCJDtleyQ"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9ef4c3d58dd4da0b623438d7c5efc7c"}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6e08ef0b","executionInfo":{"status":"ok","timestamp":1761047600388,"user_tz":-120,"elapsed":4757,"user":{"displayName":"Working Gmail","userId":"11296043961252965758"}},"outputId":"b82b7f6d-27df-4967-8251-bda40c99581f"},"source":["!pip install flash-attn --no-build-isolation"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: flash-attn in /usr/local/lib/python3.12/dist-packages (2.8.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn) (2.8.0+cu126)\n","Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn) (3.0.3)\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","# Create a pipeline\n","generator = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    return_full_text=False,\n","    max_new_tokens=200, # Reduced max_new_tokens\n","    do_sample=False,\n","    use_cache=False # Disable caching\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"metska-agBo7","executionInfo":{"status":"ok","timestamp":1761047493790,"user_tz":-120,"elapsed":250,"user":{"displayName":"Working Gmail","userId":"11296043961252965758"}},"outputId":"7b666c00-d46d-4f17-80ec-db95f39568c7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]}]},{"cell_type":"code","source":["# @title\n","# The promt (user input / query)\n","messages = [\n","    {\"role\": \"user\", \"content\": \"Create a Youtube video suggestion on how to build an LLM project.\"}\n","]\n","\n","# Generate output\n","output = generator(messages)\n","print(output[0][\"generated_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNJt5fOzi9To","executionInfo":{"status":"ok","timestamp":1761047595639,"user_tz":-120,"elapsed":94753,"user":{"displayName":"Working Gmail","userId":"11296043961252965758"}},"outputId":"7a8c63fc-ca28-4220-b48d-efe34f9ff197"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:transformers_modules.microsoft.Phi_hyphen_3_hyphen_mini_hyphen_4k_hyphen_instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"]},{"output_type":"stream","name":"stdout","text":[" Title: Building Your First Large Language Model (LLM) Project: A Step-by-Step Guide\n","\n","Description:\n","\n","Are you interested in building your own Large Language Model (LLM) project? In this video, we will walk you through the process of building your first LLM project from scratch. We will cover everything from data collection and preprocessing to model training and evaluation.\n","\n","By the end of this video, you will have a solid understanding of the LLM project development process and be able to build your own LLM project using popular machine learning frameworks like TensorFlow and PyTorch.\n","\n","Here's what we'll cover in this video:\n","\n","1. Introduction to LLMs: What are LLMs and why are they important?\n","2. Data Collection: How to collect and preprocess data for LLMs\n","3. Model Architecture: Understanding the different types of LLM architectures\n","4. Model\n"]}]}]}